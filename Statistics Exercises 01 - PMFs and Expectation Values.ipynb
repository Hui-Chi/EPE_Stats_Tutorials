{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unusual-explanation",
   "metadata": {},
   "source": [
    "# Statistics Exercises 01\n",
    "\n",
    "By Yi-Lun (Alan) Chung $^\\dagger$ and Carter Vu $^*$\n",
    "\n",
    "$^\\dagger$ National Tsing Hua University, Taiwan\n",
    "\n",
    "$^*$ University of Washington, Seattle\n",
    "\n",
    "Winter 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-worry",
   "metadata": {},
   "source": [
    "## Intro\n",
    "In this set of exercises, we will review 3 types of distributions: Gaussian/Normal distributions, Poisson distributions, and Binomial distributions. Check them out below!\n",
    "\n",
    "https://en.wikipedia.org/wiki/Normal_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Poisson_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Binomial_distribution#:~:text=In%20probability%20theory%20and%20statistics,with%20probability%20p)%20or%20failure%20("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-control",
   "metadata": {},
   "source": [
    "# Installing Packages\n",
    "\n",
    "Install conda: https://docs.conda.io/projects/conda/en/latest/user-guide/install/\n",
    "\n",
    "\n",
    "\n",
    "First, create an environment with only the packages for this tutorial, so that you can keep it separate and other installs on your system won’t interfere with it, and activate the environment so that you can access those packages.\n",
    "\n",
    "conda create --name EPE_Stats_Packages python\n",
    "\n",
    "conda activate EPE_Stats_Packages\n",
    "\n",
    "\n",
    "Now that you are in the appropriate environment, install the following packages:\n",
    "\n",
    "- conda install - c conda-forge jupyterlab (this gives you access to the full jupyterlab integrated development environment, or IDE, if you just want the base functionality you can use conda install -c conda-forge notebook)\n",
    "- conda install -c anaconda scipy\n",
    "- conda install -c conda-forge matplotlib\n",
    "- conda install -c anaconda numpy (if you don’t have it already or by default)\n",
    "\n",
    "You can use: \n",
    "- conda list to see the packages you’ve installed in this environment\n",
    "- conda info --envs to see which environments are available/you’ve created\n",
    "\n",
    "Open the notebook:\n",
    "\n",
    "jupyter-notebook PATH/TO/NOTEBOOK.ipynb or jupyter-notebook PATH/TO/DIRECTORY if you like jupyter's GUI.\n",
    "\n",
    "Heads up: eventually, we want to move to reproducing the plots in the paper here (https://arxiv.org/pdf/1007.1727.pdf), where we’ll want to have some familiarity with numpy, matplotlib, and scipy. Hold on to your hats!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-interview",
   "metadata": {},
   "source": [
    "## Exercise 1: Plot Gaussian, Poisson, binomial distribution based on some given PMFs\n",
    "\n",
    "Below are the PMFs for three different distributions. Note that the PMF is the discrete counterpart of the continuous PDF. Create a function for each distribution, and plot them using matplotlib!\n",
    "\n",
    "Probability mass function (PMF) for the normal distribution:\n",
    "\n",
    "## $$g(x|\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\,\\sigma^2}}exp[-\\frac{(x-\\mu)^2}{2\\,\\sigma^2}]$$\n",
    "\n",
    "\n",
    "Probability mass function: \n",
    "\n",
    "## $$p(x|\\mu,\\sigma) = exp[-\\mu]\\frac{\\mu^x}{x!}\\text{ for }x\\geq0$$\n",
    "\n",
    "\n",
    "Probability mass function (PMF) for the binomial distribution: \n",
    "\n",
    "## $$p(x| N) = \\frac{N!}{x!(N-x)!}\\frac{1}{2^N}\\,\\,\\,, x\\in \\text{N}$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "suffering-vitamin",
   "metadata": {},
   "source": [
    "## Exercise 2: Plot the PMFs as binned histograms instead of continuous distributions\n",
    "Note: it can help if you think about the binned histogram value as the expectation value for that bin! You can also use numpy.histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "numerical-eclipse",
   "metadata": {},
   "source": [
    "## Exercise 3: Randomly sample the PMFs to get 1000 x-values, plot them as a binned histogram\n",
    "\n",
    "This is effectively what monte-carlo simulations are doing behind the scenes, except they sample a *lot* of complex distributions to approximate the overall behavior of some variable. Try using random.uniform(0,1) as one of your inputs to your pmf!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "selected-folder",
   "metadata": {},
   "source": [
    "## Exercise 4: Normalize the histogram area to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-africa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-pickup",
   "metadata": {},
   "source": [
    "## Exercise 5: Plot the binned histogram expectation values and compare to the binned PMF. How does it change if you run it again with more events? Fewer events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
